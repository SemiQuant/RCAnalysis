{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the 7 input reads, 6 had more than one primer start and there was a media of 2 primer starts. The mean length of the reads output is XX (still TODO)\n"
     ]
    }
   ],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from fuzzysearch import find_near_matches\n",
    "import statistics\n",
    "import logging\n",
    "\n",
    "# For each read in a fastq file\n",
    "# find the positions of the primer, could be in forward or reverse orientation\n",
    "#     TODO: How to deal, look for F first then if none R, or look for both and take highest?\n",
    "#     TODO: if its the dumbell method, then we will get both reads, so it will be F then R then F etc.\n",
    "# print the number of positions found and the lengths of the resulting reads, remember the inital one if not at start\n",
    "fastq_in = \"minIon.fastq\"\n",
    "is_dumbell = False\n",
    "primer_seq = \"TCCTCCTCCGTTGTTGTTGTTG\"\n",
    "primer_seq_c = Seq(primer_seq).complement() #also .reverse_complement()\n",
    "max_d = 2\n",
    "min_len = 0\n",
    "max_len = 9999999999\n",
    "# TODO: add in filtering of the cut reads based on min max, and add summary to output stats.\n",
    "\n",
    "get_strt = lambda x: str(x).split(', ')[0].split('=')[1] # same as str(matches[1]).split(', ')[0].split('=')[1]\n",
    "read_count = 0\n",
    "primer_starts = []\n",
    "for record in SeqIO.parse(fastq_in, \"fastq\"):\n",
    "    read_count += 1\n",
    "    matches = find_near_matches(primer_seq, record.seq, max_l_dist=max_d)\n",
    "    matches_comp = find_near_matches(primer_seq_c, record.seq, max_l_dist=max_d)\n",
    "    if not is_dumbell:\n",
    "        if len(matches) > 0 and len(matches_comp) > 0:\n",
    "            if len(matches) >= len(matches_comp):\n",
    "                logging.info(\"Found forward and comp primers for read %d, using highest which is forward\" % (read_count))\n",
    "            else:\n",
    "                logging.info(\"Found forward and comp primers for read %d, using highest which is complement\" % (read_count))\n",
    "                matches = matches_comp\n",
    "        elif len(matches) < 2:\n",
    "            if len(matches_comp) >= 2: # means its comp strand sequenced\n",
    "                matches = matches_comp\n",
    "            else:\n",
    "                if len(matches) == 1 or len(matches_comp) == 1: # means there is only one read\n",
    "                    primer_starts.append(1)\n",
    "                    SeqIO.write(record, \"read_\" + str(read_count) + \"_single.fq\", \"fastq\") # this does not append\n",
    "                else:\n",
    "                    primer_starts.append(0)\n",
    "                pass\n",
    "    else:\n",
    "        matches = matches + matches_comp\n",
    "        if len(matches) < 2:\n",
    "            if len(matches) == 1 : # means there is only one read\n",
    "                primer_starts.append(1)\n",
    "                SeqIO.write(record, \"read_\" + str(read_count) + \"_single.fq\", \"fastq\") # this does not append\n",
    "            else:\n",
    "                primer_starts.append(0)\n",
    "            pass\n",
    "    # So now matches has all the info\n",
    "    strts = [0] + list(map(int, list(map(get_strt, matches)))) + [len(record.seq)]\n",
    "    strts.sort() # for the joining in dumbell method\n",
    "    \n",
    "    # lets get some stats\n",
    "    #     rem duplicates if there are because of a perfect primer start and the addition of 0 above\n",
    "    strts = list(dict.fromkeys(strts))\n",
    "    read_lngs = [j-i for i, j in zip(strts[:-1], strts[1:])]\n",
    "    #maybe do mean, sd and median IRQ.\n",
    "    logging.info(\"Mean lenth for read %d is %d, with a min of %d, a max of %d before filtering (if user selected)\" % (read_count, statistics.mean(read_lngs), min(read_lngs), max(read_lngs)))\n",
    "\n",
    "    # filter\n",
    "    if sum(1 for x in read_lngs if min_len <= x <= max_len) < 2:\n",
    "        primer_starts.append(1)\n",
    "        ext = \"_single.fq\"\n",
    "    else:\n",
    "        ext = \"_multiple.fq\"\n",
    "    \n",
    "    records_tmp = []\n",
    "    for i in range(0, len(strts)-1):\n",
    "        if min_len <= (strts[i+1]-strts[i]) <= max_len:\n",
    "            records_tmp.append(record[strts[i]:strts[i+1]])\n",
    "\n",
    "    SeqIO.write(records_tmp, \"read_\" + str(read_count) + ext, \"fastq\") # this does not append\n",
    "    # this can now be passed to the other script to make a consensus\n",
    "    primer_starts.append(len(strts)-1) #or -2?\n",
    "\n",
    "# logging.info(\"\")\n",
    "with_seq = len([i for i in primer_starts if i > 1]) \n",
    "print(\"From the %d input reads, %d had more than one primer start and there was a media of %d primer starts. The mean length of the reads output is XX (still TODO)\" % (read_count, with_seq, statistics.median(primer_starts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
