{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the 15 input reads, 11 had more than one primer start and there was a media of 2 primer starts. The mean length of the median cut reads per sample output is 179\n"
     ]
    }
   ],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from fuzzysearch import find_near_matches\n",
    "import statistics\n",
    "import logging\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# todo\n",
    "# make output folder\n",
    "\n",
    "\n",
    "# For each read in a fastq file\n",
    "# find the positions of the primer, could be in forward or reverse orientation\n",
    "# print the number of positions found and the lengths of the resulting reads, remember the inital one if not at start\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Please provide required inputs:')\n",
    "required_group = parser.add_argument_group(\"Required Arguments\")\n",
    "required_group.add_argument(\"-f\", \"--fastq\", required=True,  help=\"The full path to the fastq file (not zipped) to process. [REQUIRED]\")\n",
    "required_group.add_argument(\"-p\", \"--primer\", required=True, help=\"The sequence of the forward primer used. [REQUIRED]\")\n",
    "\n",
    "optional_group = parser.add_argument_group(\"Optional Arguments\")\n",
    "optional_group.add_argument(\"-t\", \"--is_dumbell\", action='store_true',\n",
    "                            help=\"Is this a dumbell amplicon, i.e., will it forward and comp in same sequence.\")\n",
    "optional_group.add_argument(\"-c\", \"--no_dumbell_comp\", action='store_true',\n",
    "                            help=\"If this a dumbell amplicon, should the complemtary sequence NOT be complemented?\")\n",
    "optional_group.add_argument(\"-d\", \"--distance\", default = 2, type = int,\n",
    "                            help=\"Maximum Levenshtein distance for primer search [Default: 2]\")\n",
    "optional_group.add_argument(\"-mx\", \"--min_len\", default = 2, type = int,\n",
    "                            help=\"Minimum length of cut sequence [Default: 2]\")\n",
    "optional_group.add_argument(\"-mn\", \"--max_len\", default = 9999999, type = int,\n",
    "                            help=\"Maximum length of cut sequence [Default: 9999999]\")\n",
    "optional_group.add_argument(\"-o\", \"--out\", help=\"Output folder [Default: cwd]\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "fastq_in = args.fastq\n",
    "primer_seq = args.primer\n",
    "primer_seq_c = Seq(primer_seq).complement() #also .reverse_complement()\n",
    "is_dumbell = args.is_dumbell\n",
    "dumbell_comp = args.no_dumbell_comp\n",
    "max_d = args.distance\n",
    "min_len = args.min_len\n",
    "max_len = args.max_len\n",
    "out = args.out\n",
    "\n",
    "# fastq_in = \"minIon_trial2.fastq\" #\"minIon.fastq\"\n",
    "# is_dumbell = False\n",
    "# dumbell_comp = False\n",
    "# primer_seq = \"TCCTCCTCCGTTGTTGTTGTTG\"\n",
    "# primer_seq_c = Seq(primer_seq).complement() #also .reverse_complement()\n",
    "# max_d = 2\n",
    "# min_len = 20\n",
    "# max_len = 5000\n",
    "\n",
    "if out != None:\n",
    "    if not os.path.isdir(out):\n",
    "        try:\n",
    "            os.makedirs(out, exist_ok=True)\n",
    "            os.chdir(out)\n",
    "        except:\n",
    "            print(\"Could not make dir %s\" % (out))\n",
    "\n",
    "get_strt = lambda x: str(x).split(', ')[0].split('=')[1] # same as str(matches[1]).split(', ')[0].split('=')[1]\n",
    "read_count = 0\n",
    "primer_starts = []\n",
    "passed_lengths = []\n",
    "for record in SeqIO.parse(fastq_in, \"fastq\"):\n",
    "    read_count += 1\n",
    "    matches = find_near_matches(primer_seq, record.seq, max_l_dist=max_d)\n",
    "    matches_comp = find_near_matches(primer_seq_c, record.seq, max_l_dist=max_d)\n",
    "    if not is_dumbell:\n",
    "        if len(matches) > 0 and len(matches_comp) > 0:\n",
    "            if len(matches) >= len(matches_comp):\n",
    "                logging.info(\"Found forward and comp primers for read %d, using highest which is forward\" % (read_count))\n",
    "            else:\n",
    "                logging.info(\"Found forward and comp primers for read %d, using highest which is complement\" % (read_count))\n",
    "                matches = matches_comp\n",
    "        elif len(matches) < 2:\n",
    "            if len(matches_comp) >= 2: # means its comp strand sequenced\n",
    "                matches = matches_comp\n",
    "            else:\n",
    "                if len(matches) == 1 or len(matches_comp) == 1: # means there is only one read\n",
    "                    primer_starts.append(1)\n",
    "                    SeqIO.write(record, \"read_\" + str(read_count) + \"_single.fq\", \"fastq\") # this does not append\n",
    "                else:\n",
    "                    primer_starts.append(0)\n",
    "                pass\n",
    "    else:\n",
    "        db_order = [True] * len(matches) + [False] * len(matches_comp)\n",
    "        matches = matches + matches_comp\n",
    "        if len(matches) < 2:\n",
    "            if len(matches) == 1 : # means there is only one read\n",
    "                primer_starts.append(1)\n",
    "                SeqIO.write(record, \"read_\" + str(read_count) + \"_single.fq\", \"fastq\") # this does not append\n",
    "            else:\n",
    "                primer_starts.append(0)\n",
    "            pass\n",
    "        else:\n",
    "            if db_order[-1]: # add last one\n",
    "                db_order.append(False)\n",
    "            else:\n",
    "                db_order.append(True)\n",
    "    \n",
    "    if len(matches) > 2:\n",
    "        # So now matches has all the info\n",
    "        strts = [0] + list(map(int, list(map(get_strt, matches)))) + [len(record.seq)]\n",
    "        if not(dumbell_comp):\n",
    "            [x for _,x in sorted(zip(sorted(strts[1:-1]), db_order))] # sort list based on other list\n",
    "\n",
    "        strts.sort() # for the joining in dumbell method\n",
    "\n",
    "        # lets get some stats\n",
    "        #     rem duplicates if there are because of a perfect primer start and the addition of 0 above\n",
    "        strts = list(dict.fromkeys(strts))\n",
    "#         also need to do this for \n",
    "        if not(dumbell_comp):\n",
    "            rem = [idx for idx, item in enumerate(strts[1:]) if item in strts[1:][:idx]]\n",
    "#             db_order.pop(rem) #never used pop before, it prints the one it removes, easier than db_order[x:] + db_order[x+1:]\n",
    "            db_order = [j for i, j in enumerate(db_order) if i not in rem]\n",
    "        read_lngs = [j-i for i, j in zip(strts[:-1], strts[1:])]\n",
    "        #maybe do mean, sd and median IRQ.\n",
    "        logging.info(\"Mean lenth for read %d is %d, with a min of %d, a max of %d before filtering (if user selected)\" % (read_count, statistics.mean(read_lngs), min(read_lngs), max(read_lngs)))\n",
    "\n",
    "        # filter\n",
    "        if sum(1 for x in read_lngs if min_len <= x <= max_len) < 2:\n",
    "            primer_starts.append(1)\n",
    "            ext = \"_single.fq\"\n",
    "        else:\n",
    "            ext = \"_multiple.fq\"\n",
    "\n",
    "        records_tmp = []\n",
    "        passed_lengths_ind = []\n",
    "        for i in range(0, len(strts)-1):\n",
    "            cut_len = strts[i+1] - strts[i]\n",
    "            if min_len <= cut_len <= max_len:\n",
    "                if not(dumbell_comp) and db_order[i]: # we need to the complement those reads with the complement of the primer sequence (qual score will stay the same)\n",
    "    #                 Figure out which ones they are and do this\n",
    "                    record.seq = record.seq.complement()\n",
    "                records_tmp.append(record[strts[i]:strts[i+1]])\n",
    "                passed_lengths_ind.append(cut_len)\n",
    "\n",
    "        passed_lengths.append(passed_lengths_ind)        \n",
    "        SeqIO.write(records_tmp, \"read_\" + str(read_count) + ext, \"fastq\") # this does not append\n",
    "        # this can now be passed to the other script to make a consensus\n",
    "        primer_starts.append(len(strts)-1) #or -2?\n",
    "\n",
    "diff_lens = [max(i)-min(i) for i in passed_lengths]\n",
    "logging.info(\"The median distance between the shortest and longest read lengths in the cut sequences is %d\" % statistics.median(diff_lens))\n",
    "\n",
    "with_seq = len([i for i in primer_starts if i > 1]) \n",
    "print(\"From the %d input reads, %d had more than one primer start and there was a media of %d primer starts. The mean length of the median cut reads per sample output is %d\" % (read_count, with_seq, statistics.mean(primer_starts), statistics.median([statistics.median(i) for i in passed_lengths])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from fuzzysearch import find_near_matches\n",
    "import statistics\n",
    "import logging\n",
    "import argparse\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_in = \"/Users/SemiQuant/Downloads/del/f2/f2_red.fastq\"\n",
    "primer_seq = \"CTGGTGACGCATACCGAAC\"\n",
    "primer_seq_c = Seq(primer_seq).complement() #also .reverse_complement()\n",
    "is_dumbell = True\n",
    "dumbell_comp = False\n",
    "max_d = 2\n",
    "min_len = 600\n",
    "max_len = 800\n",
    "out = \"/Users/SemiQuant/Downloads/del/f2/test\"\n",
    "\n",
    "\n",
    "if out != None:\n",
    "    if not os.path.isdir(out):\n",
    "        try:\n",
    "            os.makedirs(out, exist_ok=True)\n",
    "            os.chdir(out)\n",
    "        except:\n",
    "            print(\"Could not make dir %s\" % (out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "StatisticsError",
     "evalue": "no median for empty data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStatisticsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-16a00628280a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mdiff_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpassed_lengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The median distance between the shortest and longest read lengths in the cut sequences is %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mwith_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprimer_starts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.8/3.8.3_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/statistics.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mStatisticsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no median for empty data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStatisticsError\u001b[0m: no median for empty data"
     ]
    }
   ],
   "source": [
    "get_strt = lambda x: str(x).split(', ')[0].split('=')[1] # same as str(matches[1]).split(', ')[0].split('=')[1]\n",
    "read_count = 0\n",
    "primer_starts = []\n",
    "passed_lengths = []\n",
    "for record in SeqIO.parse(fastq_in, \"fastq\"):\n",
    "    read_count += 1\n",
    "    matches = find_near_matches(primer_seq, record.seq, max_l_dist=max_d)\n",
    "    matches_comp = find_near_matches(primer_seq_c, record.seq, max_l_dist=max_d)\n",
    "    if not is_dumbell:\n",
    "        if len(matches) > 0 and len(matches_comp) > 0:\n",
    "            if len(matches) >= len(matches_comp):\n",
    "                logging.info(\"Found forward and comp primers for read %d, using highest which is forward\" % (read_count))\n",
    "            else:\n",
    "                logging.info(\"Found forward and comp primers for read %d, using highest which is complement\" % (read_count))\n",
    "                matches = matches_comp\n",
    "        elif len(matches) < 2:\n",
    "            if len(matches_comp) >= 2: # means its comp strand sequenced\n",
    "                matches = matches_comp\n",
    "            else:\n",
    "                if len(matches) == 1 or len(matches_comp) == 1: # means there is only one read\n",
    "                    primer_starts.append(1)\n",
    "                    SeqIO.write(record, \"read_\" + str(read_count) + \"_single.fq\", \"fastq\") # this does not append\n",
    "                else:\n",
    "                    primer_starts.append(0)\n",
    "                pass\n",
    "    else:\n",
    "        db_order = [True] * len(matches) + [False] * len(matches_comp)\n",
    "        matches = matches + matches_comp\n",
    "        if len(matches) < 2:\n",
    "            if len(matches) == 1 : # means there is only one read\n",
    "                primer_starts.append(1)\n",
    "                SeqIO.write(record, \"read_\" + str(read_count) + \"_single.fq\", \"fastq\") # this does not append\n",
    "            else:\n",
    "                primer_starts.append(0)\n",
    "            pass\n",
    "        else:\n",
    "            if db_order[-1]: # add last one\n",
    "                db_order.append(False)\n",
    "            else:\n",
    "                db_order.append(True)\n",
    "    \n",
    "    if len(matches) > 2:\n",
    "        # So now matches has all the info\n",
    "        strts = [0] + list(map(int, list(map(get_strt, matches)))) + [len(record.seq)]\n",
    "        if not(dumbell_comp):\n",
    "            [x for _,x in sorted(zip(sorted(strts[1:-1]), db_order))] # sort list based on other list\n",
    "\n",
    "        strts.sort() # for the joining in dumbell method\n",
    "\n",
    "        # lets get some stats\n",
    "        #     rem duplicates if there are because of a perfect primer start and the addition of 0 above\n",
    "        strts = list(dict.fromkeys(strts))\n",
    "#         also need to do this for \n",
    "        if not(dumbell_comp):\n",
    "            rem = [idx for idx, item in enumerate(strts[1:]) if item in strts[1:][:idx]]\n",
    "#             db_order.pop(rem) #never used pop before, it prints the one it removes, easier than db_order[x:] + db_order[x+1:]\n",
    "            db_order = [j for i, j in enumerate(db_order) if i not in rem]\n",
    "        read_lngs = [j-i for i, j in zip(strts[:-1], strts[1:])]\n",
    "        #maybe do mean, sd and median IRQ.\n",
    "        logging.info(\"Mean lenth for read %d is %d, with a min of %d, a max of %d before filtering (if user selected)\" % (read_count, statistics.mean(read_lngs), min(read_lngs), max(read_lngs)))\n",
    "\n",
    "        # filter\n",
    "        if sum(1 for x in read_lngs if min_len <= x <= max_len) < 2:\n",
    "            primer_starts.append(1)\n",
    "            ext = \"_single.fq\"\n",
    "        else:\n",
    "            ext = \"_multiple.fq\"\n",
    "\n",
    "        records_tmp = []\n",
    "        passed_lengths_ind = []\n",
    "        for i in range(0, len(strts)-1):\n",
    "            cut_len = strts[i+1] - strts[i]\n",
    "            if min_len <= cut_len <= max_len:\n",
    "                if not(dumbell_comp) and db_order[i]: # we need to the complement those reads with the complement of the primer sequence (qual score will stay the same)\n",
    "    #                 Figure out which ones they are and do this\n",
    "                    record.seq = record.seq.complement()\n",
    "                records_tmp.append(record[strts[i]:strts[i+1]])\n",
    "                passed_lengths_ind.append(cut_len)\n",
    "\n",
    "        passed_lengths.append(passed_lengths_ind)        \n",
    "        SeqIO.write(records_tmp, \"read_\" + str(read_count) + ext, \"fastq\") # this does not append\n",
    "        # this can now be passed to the other script to make a consensus\n",
    "        primer_starts.append(len(strts)-1) #or -2?\n",
    "try:\n",
    "    diff_lens = [max(i)-min(i) for i in passed_lengths]\n",
    "    logging.info(\"The median distance between the shortest and longest read lengths in the cut sequences is %d\" % statistics.median(diff_lens))\n",
    "    with_seq = len([i for i in primer_starts if i > 1]) \n",
    "    print(\"From the %d input reads, %d had more than one primer start and there was a media of %d primer starts. The mean length of the median cut reads per sample output is %d\" % (read_count, with_seq, statistics.mean(primer_starts), statistics.median([statistics.median(i) for i in passed_lengths])))\n",
    "except:\n",
    "    print(\"cant calc median, probaly no data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
